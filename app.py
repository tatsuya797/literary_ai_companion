import streamlit as st
import openai
from pathlib import Path
import zipfile
import chardet  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•æ¤œå‡ºãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from aozora_preprocess import save_cleanse_text  # å‰å‡¦ç†ã®é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

author_id = '000879'
author_name = 'èŠ¥å·é¾ä¹‹ä»‹'

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
zip_files_directory = Path("./000879/files")  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æŒ‡å®š
unzip_dir = Path("unzipped_files")  # è§£å‡å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
unzip_dir.mkdir(exist_ok=True, parents=True)  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ

# è§£å‡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§å–å¾—
def get_text_files():
    text_files = list(unzip_dir.glob("**/*.txt"))  # å†å¸°çš„ã«.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    if not text_files:
        st.error("è§£å‡å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    return text_files

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡
def extract_zip_files():
    zip_files = list(zip_files_directory.glob("*.zip"))
    if not zip_files:
        st.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {zip_files_directory}")
        return

    for zip_file in zip_files:
        try:
            with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                zip_ref.extractall(unzip_dir)  # è§£å‡
            st.success(f"ZIPãƒ•ã‚¡ã‚¤ãƒ« {zip_file.name} ã‚’è§£å‡ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            st.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®è§£å‡ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
def load_text(file_path):
    try:
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            encoding = chardet.detect(raw_data)['encoding']
        
        with open(file_path, 'r', encoding=encoding) as f:
            return f.read()
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return ""

# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
def process_text_files():
    processed_texts = []
    text_files = get_text_files()

    if not text_files:
        return []

    for text_file in text_files:
        cleaned_df = save_cleanse_text(text_file, unzip_dir)
        if cleaned_df is not None:
            processed_texts.append(cleaned_df.to_string(index=False))

    return processed_texts

# ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼
extract_zip_files()  # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡

all_texts = ""
for text_file in get_text_files():
    all_texts += load_text(text_file) + "\n"

# ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
if all_texts.strip():
    st.text_area("è§£å‡ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿", all_texts, height=300)
else:
    st.warning("ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# æ•´å½¢å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ãƒ»è¡¨ç¤º
processed_texts = process_text_files()
if processed_texts:
    for i, text in enumerate(processed_texts):
        st.text_area(f"æ•´å½¢å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ {i+1}", text, height=300)
else:
    st.warning("æ•´å½¢å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè¨­å®š
openai.api_key = st.secrets.OpenAIAPI.openai_api_key

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": f"{author_name} ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¸ã‚ˆã†ã“ãï¼"}
    ]

def communicate():
    messages = st.session_state["messages"]
    user_message = {"role": "user", "content": st.session_state["user_input"]}
    messages.append(user_message)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo", messages=messages
    )
    bot_message = response["choices"][0]["message"]
    messages.append(bot_message)
    st.session_state["user_input"] = ""

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®UI
st.title(f"{author_name} ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.text_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="user_input", on_change=communicate)

if st.session_state["messages"]:
    for message in reversed(st.session_state["messages"][1:]):
        speaker = "ğŸ™‚" if message["role"] == "user" else "ğŸ¤–"
        st.write(f"{speaker}: {message['content']}")
